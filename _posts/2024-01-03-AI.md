---
layout: post
title:  "人工智能期末复习"
date:   2023-01-03 19:00:00 +0800
categories: AI chinese
---

6-7个简答题，每个题15-20分，搜索出一题，
## 搜索
井字棋，拼图等。

### 构建启发式函数
为什么需要启发：
1. 没有精确解
2. 约简搜索的状态空间

例：井字棋。以落子位置能够覆盖的路线数量作为启发函数。
- 在角上落子，覆盖三种路线；
- 在中间落子，覆盖四种路线；
- 在边上落子，覆盖两种路线。
优先对中间位置进行搜索。

### 博弈树、极小极大搜索
- 极大，MAX：代表我方玩家，要最大化收益
- 极小，MIN：代表对手，最小化我方收益

将评估值（启发值）自底向上传播。
- 如果父状态是MAX，将孩子节点中的最大值传给它
- 如果父状态是MIN，将孩子节点中的最小值传给它

#### 固定层深的极小极大过程
在每次决策时，只搜索固定的层深。
例如，当固定层深为2时，搜索两层就停止，以子节点的子节点作为搜索树的叶子，叶节点用启发式函数估算价值。然后向上回溯，用MIN-MAX方法计算每一层的评估值。

### α-β剪枝

Alpha表示一个MAX节点的估值，Beta表示一个MIN节点的估值。这两个值在搜索过程中不断更新。MAX节点的 Alpha会越来越大，MIN节点的Beta会越来越小。

- Alpha剪枝：任一MIN节点，如果其Beta值已经小于等于其祖先MAX节点的Alpha值，则停止搜索。
- Beta剪枝：任一MAX节点，如果其Alpha值已经大于等于其祖先MIN节点的Beta值，则停止搜索。

这种剪枝对子节点的排序非常敏感。

### A*算法。
评估函数：
$$f(n) = g(n) + h(n)$$
- $g(n)$是已知节点$n$距离起点的代价。
- $h(n)$是$n$距离终点的预计代价，这是一个启发函数。
- $f(n)$时综合优先级，在选择下一个要遍历的节点时，总会选取综合优先级$f(n)$最小的节点。

把最优评估函数记为：
$$f^*(n) = g^*(n) + h^*(n)$$
- 由于还没有遍历完整张图，所以$g(n) \geq g^*(n)$。
- $h(n) \leq h^*(n)$时，一定能找到最短路径。此时称为$A*$算法。

## 自动推理
掌握合一的方式，怎么做合一归纳归结原理，变成几句话，命题、一阶谓词逻辑，证明

## 知识表示

### 产生式系统
#### 产生式规则
产生式：一组产生式，互相配合/协调，其中一个产生式产生的结论可以作为另一个产生式的事实使用，以求解问题。

#### 主要架构
产生式系统由数据库、规则库、控制系统构成。
- 数据库：存放问题求解过程中的各种信息的数据结构，包括初始状态、原始证据、中间结论、最终结论。其内容在推理过程中在动态、不断变化的。
- 规则库：有效表达领域内的过程性知识。对知识进行合理的组织与管理，提高问题求解效率。
- 控制系统：从规则库中选择规则，并与数据库中的已知事实进行匹配。发生冲突时调用相应策略进行消解。如果执行规则的右部是一个或多个结论，则将结论加入到数据库中。如果执行规则的右部是一个或多个的操作，则执行这些操作，并将操作产生的事实加入到数据库中。对不确定性的知识，要计算结论的不确定性。在适当时候终止系统运行。

### 构造、推理

## 不确定性推理
PPT上练习题，DS证据理论，分配函数、怎么做归一，证据合并

## 贝叶斯网络

### 贝叶斯定理
帮助我们在知道结果的时候反推原因。

推导：
$$P(H|E) = \frac{P(HE)}{P(E)}$$
$$P(E|H) = \frac{P(HE)}{P(H)}$$

综合以上两个公式，可得
$$P(H|E) = \frac{P(E|H)P(H)}{P(E)}$$
即贝叶斯定理。

考虑事件$H_1, H_2, \dots, H_n$，可以得到更一般的形式
$$P(H_i|E) = \frac{P(E|H_i)P(H_i)}{\sum_{k=1}^nP(E|H_k)P(H_k)}$$

### 贝叶斯网络推理

- 有向无环图
- 节点代表随机变量
- 边代表节点间的因果关系，用条件概率表达关系的强弱
- 没有父节点的用先验概率表达信息

前向推理、后向推理，给贝叶斯网络图来计算和做因果推理

### 贝叶斯网络独立性
（哪几个点独立，在什么情况下独立/不独立）

## 马尔可夫网络（和贝叶斯网只会考一个）
和贝叶斯网的异同（贝叶斯有的构造不出来，例子），变量消除联合概率计算
符号学习：决策树，掌握基本的给一批数据，算信息熵，信息增益，分裂节点，构造决策树

## 神经网络
做BP网络，梯度回传，隐层节点怎么做梯度回传，基本概念

### 为什么一层网络不能解决异或问题
单层的神经网络只能解决线性问题，即可以用一条直线（平面、超平面）划分的问题。然而，异或问题不是线性的，因此需要多层神经网络才能解决。

## 遗传算法：基本操作算子，如交叉、变异等等

### MDP模型
MDP即Markov Decision Process（马尔科夫决策过程）。
机器处于环境$E$中，状态空间为$X$，动作空间$A$，转移函数$P: X \times A \times X \to \mathbb{R}$使得环境从当前状态按某种概率转移到另一个状态，在转移的同时，环境会根据潜在的奖赏函数$R: X \times X \to R$反馈给机器一个奖赏。
综合起来，强化学习任务对应了马尔科夫四元组$E=<X, A, P, R>$。

### 贝尔曼等式与动态规划

## 博弈：

### 帕累托优
- 若某资源配置下，存在一种调整可以使得所有人的境况都不变差的前提下，有至少一个人的境况变好，则该资源配置不是帕累托最优。
- 反之，若不存在这样的调整，则该配置可以被称作帕累托最优。

### 纳什均衡
给定其他博弈者策略不变，每一个博弈者都没有动机改变自己的策略，即使改变策略也不会提高自身的收益。此时各博弈者的策略组合称为纳什均衡。

### 给一个投票算结果


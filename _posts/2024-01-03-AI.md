---
layout: post
title:  "人工智能期末复习"
date:   2023-01-03 19:00:00 +0800
categories: AI chinese
---

6-7个简答题，每个题15-20分，搜索出一题，
## 搜索
井字棋，拼图等。

### 构建启发式函数
为什么需要启发：
1. 没有精确解
2. 约简搜索的状态空间

例：井字棋。以落子位置能够覆盖的路线数量作为启发函数。
- 在角上落子，覆盖三种路线；
- 在中间落子，覆盖四种路线；
- 在边上落子，覆盖两种路线。
优先对中间位置进行搜索。

### 博弈树、极小极大搜索
- 极大，MAX：代表我方玩家，要最大化收益
- 极小，MIN：代表对手，最小化我方收益

将评估值（启发值）自底向上传播。
- 如果父状态是MAX，将孩子节点中的最大值传给它
- 如果父状态是MIN，将孩子节点中的最小值传给它

#### 固定层深的极小极大过程
在每次决策时，只搜索固定的层深。
例如，当固定层深为2时，搜索两层就停止，以子节点的子节点作为搜索树的叶子，叶节点用启发式函数估算价值。然后向上回溯，用MIN-MAX方法计算每一层的评估值。

### α-β剪枝

Alpha表示一个MAX节点的估值，Beta表示一个MIN节点的估值。这两个值在搜索过程中不断更新。MAX节点的 Alpha会越来越大，MIN节点的Beta会越来越小。

- Alpha剪枝：任一MIN节点，如果其Beta值已经小于等于其祖先MAX节点的Alpha值，则停止搜索。
- Beta剪枝：任一MAX节点，如果其Alpha值已经大于等于其祖先MIN节点的Beta值，则停止搜索。

这种剪枝对子节点的排序非常敏感。

### A*算法。



## 自动推理
掌握合一的方式，怎么做合一归纳归结原理，变成几句话，命题、一阶谓词逻辑，证明

## 知识表示
产生式系统，产生式规则及主要架构，构造、推理

## 不确定性推理
PPT上练习题，DS证据理论，分配函数、怎么做归一，证据合并

## 贝叶斯网络

### 贝叶斯定理
帮助我们在知道结果的时候反推原因。

推导：
$$P(H|E) = \frac{P(HE)}{P(E)}$$
$$P(E|H) = \frac{P(HE)}{P(H)}$$

综合以上两个公式，可得
$$P(H|E) = \frac{P(E|H)P(H)}{P(E)}$$
即贝叶斯定理。

考虑事件$H_1, H_2, \dots, H_n$，可以得到更一般的形式
$$P(H_i|E) = \frac{P(E|H_i)P(H_i)}{\sum_{k=1}^nP(E|H_k)P(H_k)}$$

### 贝叶斯网络推理

- 有向无环图
- 节点代表随机变量
- 边代表节点间的因果关系，用条件概率表达关系的强弱
- 没有父节点的用先验概率表达信息

前向推理、后向推理，给贝叶斯网络图来计算和做因果推理

### 贝叶斯网络独立性
（哪几个点独立，在什么情况下独立/不独立）

## 马尔可夫网络（和贝叶斯网只会考一个）
和贝叶斯网的异同（贝叶斯有的构造不出来，例子），变量消除联合概率计算
符号学习：决策树，掌握基本的给一批数据，算信息熵，信息增益，分裂节点，构造决策树

## 神经网络
做BP网络，梯度回传，隐层节点怎么做梯度回传，基本概念

### 为什么一层网络不能解决异或问题
单层的神经网络只能解决线性问题，即可以用一条直线（平面、超平面）划分的问题。然而，异或问题不是线性的，因此需要多层神经网络才能解决。

## 遗传算法：基本操作算子，如交叉、变异等等

### MDP模型
MDP即Markov Decision Process（马尔科夫决策过程）。
机器处于环境$E$中，状态空间为$X$，动作空间$A$，转移函数$P: X \times A \times X \to \mathbb{R}$使得环境从当前状态按某种概率转移到另一个状态，在转移的同时，环境会根据潜在的奖赏函数$R: X \times X \to R$反馈给机器一个奖赏。
综合起来，强化学习任务对应了马尔科夫四元组$E=<X, A, P, R>$。


动态规划，贝尔曼等式，PPT上例子计算

## 博弈：

### 帕累托优
- 若某资源配置下，存在一种调整可以使得所有人的境况都不变差的前提下，有至少一个人的境况变好，则该资源配置不是帕累托最优。
- 反之，若不存在这样的调整，则该配置可以被称作帕累托最优。

### 纳什均衡
给定其他博弈者策略不变，每一个博弈者都没有动机改变自己的策略，即使改变策略也不会提高自身的收益。此时各博弈者的策略组合称为纳什均衡。

### 给一个投票算结果


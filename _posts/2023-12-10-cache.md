---
layout: post
title:  "缓存理解要点"
date:   2023-12-10 09:00:00 +0800
categories: arch chinese
---

## 概念部分

### 1. 什么是组相连、全相连、直接相连

### 2. 组相连中 Way、Set、Offset 的含义

### 3. 缓存为什么以 CacheBlock (Cacheline) 为单位进行管理，L1/L2/L3 是否能用不同 Size 的 CacheBlock

### 4. 维护 Cache Coherence 的两种策略： Directory、Snoop

### 5. 非阻塞的缓存一定中“非阻塞”的含义，它一直是非阻塞的嘛？

### 6. 缓存包含关系 Inclusive、Non-inclusive、Exclusive 的含义（与各自优势）

### 7. 预取算法、替换算法在缓存中发挥哪些作用？

## 总线部分
（括号中为可参考的手册页数，手册版本为 TileLink SPEC 1.8.1）

### 1. ABCDE 各条通道的方向与优先级，它们分别用来传递什么信息

A通道和D通道是两个基本通道。
- A通道：从master到slave，发送对指定地址范围进行操作的请求，访问或缓存数据。
- D通道：从slave到master，向原始请求者发送数据响应或确认消息。

TL-C通道引入了B、C、E三个通道。
- B通道：从slave到master，发送请求，请求在一个被master缓存的地址上执行操作，访问或回写缓存的数据。
- C通道：从master到slave，发送数据或确认信息以响应请求。
- E通道：从master到slave，从原始请求者发送缓存块传输的最终确认，用于序列化。

消息跨通道的优先级依次为A < B < C < D < E。

### 2. 各个总线 Opcode 的语义

![TileLink op](https://github.com/yu-yake2002/yu-yake2002.github.io/raw/main/pictures/tilelink-op.png)

### 3. 缓存块的状态有几种，它们是怎么发生状态转移的（P61-P64）

- Nothing：没有缓存数据副本，没有读写权限。
- Trunk：在Tip和Root之间的路径上拥有缓存副本的节点。此副本的数据可能不是最新的，因此不具有其副本的读写权限。
- Tip：包含最新的数据。
  - Tip with no Branches：具有读写权限。可能有脏数据。
  - Tip with Branches：由于上面还有branch，所以只有读权限。可能有脏数据。如果想要写权限，就要把上面的branch清掉。
- Branch：在Tip结点之上，具有只读的副本，不具有脏数据。

![Coherence tree](https://github.com/yu-yake2002/yu-yake2002.github.io/raw/main/pictures/tilelink-tree.png)

### 4. 为什么请求之间会有“打断”的问题

保证数据的正确性，且避免死锁。

#### Probe 打断 Acquire 的重要性（P69）

当Slave收到ProbeAck之后才能向主端发送Grant。

![Probe and Acquire](https://github.com/yu-yake2002/yu-yake2002.github.io/raw/main/pictures/Probe-Acquire.png)

1. 主代理A先发送Acquire，但由于网络延迟，后到达从代理。
2. 主代理B后发送Acquire，但先到达从代理，被序列化在A的前面。
3. 从代理向A发送Probe，Slave的Grant必须包含最新数据，所以Probe的优先级要高于Acquire。即使A还在等待Grant，A也必须先处理Probe，以避免死锁。
4. 从代理接收到A的ProbeAck后，向B发送Grant。
5. 从代理接收到A的Acquire，但由于正等待B的GrantAck，所以现在还不能处理这个请求。
6. 一旦接收到B的GrantAck，A的事务就可以正常处理了。
7. 从代理向B发送Probe，但这个操作被在上一个Grant之后。
8. 从代理向A发送合适类型的Grant(包括数据副本)，说明A在Acquire后被Probe过。

#### Release 请求打断 Probe 的重要性（P69）

如果Master在一个块上有一个未完成的Release事务，它就不能用ProbeAcks响应此块上传入的探测请求，直到它从Slave收到一个ReleaseAck，确认回写完成。

![Probe and Acquire](https://github.com/yu-yake2002/yu-yake2002.github.io/raw/main/pictures/Release-Probe.png)

1. 主代理A向从代理发送Acquire。
2. 与此同时，主代理B通过Release主动剔除相同的数据缓存块。
3. 从代理向B发送Probe。
4. 从代理等待每个发送出的Probe，但可以处理主动发起的Release。从代理发送ReleaseAck确认主动写回的操作完成。
5. B在接收到写回确认前不处理Probe。
6. 在从代理接收到B的ProbeAck后，A的事务就可以正常执行了。

### 6. 为什么 Grant 和 Release 后续都需要分别跟一个 GrantAck 和 ReleaseAck（P69）

假设将消息点到点、有序地传递到特定的代理，那么Slave只需将Grant消息发送到原始的Master就足够了。
Slave可以处理块上的后续事务。
对同一Master的后续Probe和Grant将按顺序到达。
由于不能保证这种排序，因此我们转而依赖GrantAck消息来允许从Slave序列化这两个事务。

ReleaseAck同理。

## CPL2 部分
参考代码为 CPL2 的 master 分支 https://github.com/OpenXiangShan/CoupledL2

### 1. 缓存总体框架

顶层模块：`src/main/scala/coupledL2/CoupledL2.scala`。
其中例化了`Prefetcher`、`Slice`、`Arbiter`，以及`TopDownMonitor`。
- `Prefetcher`，用于预取
- `Slice`，把缓存分成若干个`Slice`，可以提升并行性
- `Arbiter`，此处是`l1Hint_arb`
- `TopDownMonitor`，用于性能监控

其中`Slice`是最重要的模块。
每个`Slice`中包含了`RequestArb`、`MainPipe`、`SinkA-C`、`SourceC`、`DataStorage`、`Directory`、`RequestBuffer`、`MSHRCtl`、`MSHRBuffer`等模块。
- `MSHR`，即 Miss Status Holding Registers
- `Directory`，存储tag以及其他元数据
- `DataStorage`，一块SRAM，用于存储缓存的数据
- `RequestArb`，详见3
- `MainPipe`，详见3
- `GrantBuffer`，详见7
- `RefillBuffer`，详见8
- `ReleaseBuffer`，详见8

### 2. 请求的处理流程

#### 收到 L1 Acquire，且命中

1. L1 由 A 通道向 L2 发送 Acquire。`sinkA`接收请求，转换为 Cache 内部请求`TaskBundle`，发送给`RequestBuffer`。
2. 经过`RequestBuffer`的缓冲，请求传入`RequestArb`，由`RequestArb`进行仲裁。
3. 这个请求在某个周期被`RequestArb`选中。`RequestArb`在s1读取`Directory`，目录的查询结果在 s3 返回给`MainPipe`，结果为命中。
4. `MainPipe`执行实际的操作。对于`AcquirePerm`来说，`MainPipe`只需修改`Directory`即可。若是`AcquireBlock`，还需要从`DataStorage`读取数据。
5. `Acquire`操作本身完成，接下来`MainPipe`要从 D 通道发送`Grant`，这个`Grant`会发送给`GrantBuffer`，由`GrantBuffer`发送给 L1。
6. 最终 L1 由 E 通道发送`GrantAck`以确认，由`GrantBuffer`接收并且处理。

#### 收到 L1 Acquire，且缺失，需要从 L3 获取

1. `Directory`在 s3 返回给`MainPipe`的结果是缺失。此时需要分配`MSHR`，以向 L3 发送`Acquire`。`MainPipe`向`MSHRCtl`发送分配请求。
2. 执行 refill 流程。`MSHRCtl`由 A 通道向 L3 发送 `Acquire`。L3 向 L2 发送`Grant`，`RefillUnit`处理`Grant`，转发给`MSHRCtl`，写入`RefillBuffer`，并且向 L3 发送`GrantAck`。
3. 接下来，`RequestArb`进行仲裁，选中`MSHR`中的refill请求。由`MainPipe`在 s3 读`RefillBuffer`写入`DataStorage`，完成 refill 流程，同时向 L1 发送`Grant`。后续流程与命中的情况类似。

#### b 的基础上 + 需要替换

1. 还需要在 C 通道发送一个`Release`请求。`RequestArb`仲裁时选择`MSHR`发出的`Release`请求，发送给`MainPipe`。
2. `MainPipe`在 s3 从 `SourceC` 发送 `Release`。

#### 收到 L3 Probe， 且需要去 Probe L1

1. L3 由 B 通道向 L2 发送`Probe`。`sinkB`接收请求，转换为 Cache 内部请求`TaskBundle`，发送给`RequestArb`，等待`RequestArb`仲裁。
2. 这个`Probe`请求在某个时钟周期被`RequestArb`选中，在 s1 读`Directory`。读取结果在 s3 返回给`MainPipe`。根据读`Directory`的结果，`MainPipe`需要去`Probe` L1。此时分配`MSHR`。
3. `MSHRCtl`通过 B 通道向 L1 发送`Probe`。L1 通过 C 通道回复的`ProbeAck`被`sinkC`接收。
4. `MainPipe`在 s3 可能还要写`Directory`。

### 3. ReqArb / MainPipe 包含几个流水级，分别完成什么任务

`RequestArb`对来自`MSHR`、`sinkA`（`RequestBuffer`）、`sinkB`、`sinkC`的请求进行仲裁，分为s0、s1、s2。
- s0，从`MSHR`接收请求。锁存一拍，传入s1。
- s1，仲裁，优先级顺序：`MSHR`>`sinkC`>`sinkB`>`sinkA`
  - 把状态以及选出的任务信息发送给`MainPipe`
  - 向`Directory`发送查询
  - 向`RequestBuffer`发送信息
- s2，向`MainPipe`发送信息，读`RefillBuffer`和`ReleaseBuffer`

`MainPipe`是主流水线，分为s1、s2、s3、s4、s5
- s1，接收`RequestArb`的请求与状态
- s2，接收`RequestArb`的请求，读`sinkC`(`bufRead`)
- s3，从`Directory`、`RefillBuffer`、`ReleaseBuffer`接收查询结果，根据结果做以下事情
  - 写入`Directory`
  - 向`DataStorage`发送读写请求
  - 向`MSHRCtl`请求分配`MSHR`
- s4，读取`MSHR`的分配结果
- s5，从`DataStorage`获得数据，写`RefillBuffer`和`ReleaseBuffer`，把 D 通道请求发给`GrantBuffer`

### 4. Directory 目录项包含哪些内容

```scala
class MetaEntry(implicit p: Parameters) extends L2Bundle {
  val dirty = Bool()
  val state = UInt(stateBits.W)
  val clients = UInt(clientBits.W)  // valid-bit of clients
  // TODO: record specific state of clients instead of just 1-bit
  val alias = aliasBitsOpt.map(width => UInt(width.W)) // alias bits of client
  val prefetch = if (hasPrefetchBit) Some(Bool()) else None // whether block is prefetched
  val prefetchSrc = if (hasPrefetchSrc) Some(UInt(PfSource.pfSourceBits.W)) else None // prefetch source
  val accessed = Bool()

  def =/=(entry: MetaEntry): Bool = {
    this.asUInt =/= entry.asUInt
  }
}
```

- `dirty`，脏位
- `state`，分为`INVALID`、`BRANCH`、`TRUNK`、`TIP`四种
- `clients`，clients 的有效位
- `alias`，解决 Cache 别名问题
- `prefetch`位，表示这个 block 是不是被预取的
- `prefetchSrc`，预取的来源
- `accessed`

### 5. 状态机的逻辑
- s_ 表示要调度的请求，w_ 表示要等待的应答
- 设置逻辑：在 MainPipe 最后的 alloc_state 部分
- 控制子请求的逻辑：MSHR 中

### 6. 流水线入口阻塞逻辑（ReqArb 里的 BlockA/B/C）
- *如何支持同 set 请求的并发处理（新请求进入主流水线的条件，什么时候需要阻塞新请求）

### 7. GrantBuffer 的作用
- 向上层返回响应（D 通道，一个缓存块包含两个总线上的数据 beat）
- 接收 GrantAck（E 通道）
- 阻塞流水线入口（反压控制）

### 8. RefillBuffer 和 ReleaseBuffer 的作用

#### RefillBuffer

参考[香山文档](https://xiangshan-doc.readthedocs.io/zh-cn/latest/huancun/misc/)。
为了减少 Cache Miss的延迟，huancun 使用 Refill Buffer 来缓冲从下层 Cache 或 Memory 中 Refill 的数据， 这样 Refill 的数据不需要先写入 SRAM 就可以直接返回给上层 Cache。

#### ReleaseBuffer



### 9. 如何实现高优先级请求对低优先级请求的嵌套

### 10. Cache 别名问题是什么，怎么解决的

参考[香山文档](https://xiangshan-doc.readthedocs.io/zh-cn/latest/huancun/cache_alias/)。
Cache 别名问题：当两个虚页映射到同一个物理页时，如果不做额外处理的话，通过 VIPT 索引 (Virtual Index Physical Tag) 后这两个虚页会位于 cache 不同的 set，导致同一个物理页在 cache 中缓存了两份，造成一致性错误。

例如，对于 128KB，8 路组相联的 ICache 来说，每路 16KB。此时 Index 和 Offset 一共有 14 位，超过了 12 位的 page offset。超出的 2 位称为别名位。

![Cache Alias](https://xiangshan-doc.readthedocs.io/zh-cn/latest/figs/huancun_cache_alias-1.jpg)

具体的解决方式是由 L2 Cache 保证一个物理块在上层的一个 VIPT cache 中最多只有一种别名位。
下面举一个例子说明 L2 如何解决 cache 别名问题。
如下图所示，DCache 中有有一个虚地址为 0x0000 的块。
虚地址 0x0000 和 0x1000 映射到了同一个物理地址，且这两个地址的别名是不一样的。
此时 DCache 向 L2 Acquire 了地址为 0x1000 的块，并在 Acquire 请求的 user 域中记录了别名 (0x1)。
L2 在读目录后发现请求命中，但是 Acquire 的别名 (0x1) 和 L2 记录的 DCache 在该物理地址的别名 (0x0) 不同。
于是， L2 会发起一个 Probe 子请求，并在 Probe 的 data 域中记录要 probe 下来的别名 (0x0)；Probe 子请求完成后，L2 再将这个块返回给 DCache，并将 L2 client directory 中的别名改为 (0x1)。

![Alias Solution](https://xiangshan-doc.readthedocs.io/zh-cn/latest/figs/huancun_cache_alias-2.jpg)

### 11. *预取请求的处理
